import torch
import torch.nn as nn
import torch.nn.functional as F
from clip import clip

class CalShift(nn.Module):
    def __init__(self, clip_model, lambda_fim=0.4, lambda_cmp=0.4):
        super().__init__()
        self.clip_model = clip_model
        self.lambda_fim = lambda_fim  # Fisher Information weight
        self.lambda_cmp = lambda_cmp  # Confidence Misalignment weight
        
        # Freeze CLIP parameters
        for param in self.clip_model.parameters():
            param.requires_grad = False
            
        # Initialize learnable prompts if using prompt tuning
        self.prompt_learner = None  # Would be initialized for CoOp-style learning

    def compute_fisher_penalty(self, logits, labels):
        """
        Compute Fisher Information Matrix penalty
        Args:
            logits: Model output logits [batch_size, num_classes]
            labels: Ground truth labels [batch_size]
        Returns:
            fisher_penalty: Scalar penalty term
        """
        probs = F.softmax(logits, dim=-1)
        batch_size, num_classes = logits.shape
        
        # Compute gradients of log probs w.r.t. parameters
        grad_log_probs = []
        for i in range(batch_size):
            log_prob = torch.log(probs[i, labels[i]])
            grad = torch.autograd.grad(log_prob, self.prompt_learner.parameters(), 
                                     retain_graph=True, create_graph=True)
            grad_log_probs.append(torch.cat([g.view(-1) for g in grad]))
            
        grad_log_probs = torch.stack(grad_log_probs)  # [batch_size, num_params]
        
        # Compute empirical Fisher Information
        fisher_info = torch.mean(grad_log_probs.norm(dim=1)**2)
        return fisher_info

    def compute_cmp(self, logits, labels):
        """
        Compute Confidence Misalignment Penalty
        Args:
            logits: Model output logits [batch_size, num_classes]
            labels: Ground truth labels [batch_size]
        Returns:
            cmp_loss: Scalar penalty term
        """
        probs = F.softmax(logits, dim=-1)
        batch_size = logits.size(0)
        
        cmp_loss = 0.0
        for i in range(batch_size):
            true_prob = probs[i, labels[i]]
            # Sum probabilities of classes with higher prob than true class
            mask = (probs[i] > true_prob) & (torch.arange(probs.size(1)) != labels[i])
            excess_prob = probs[i][mask].sum()
            
            if excess_prob > 0:
                cmp_loss += true_prob / excess_prob
                
        return cmp_loss / batch_size

    def forward(self, images, text_tokens, labels):
        # Get image and text features
        image_features = self.clip_model.encode_image(images)
        text_features = self.clip_model.encode_text(text_tokens)
        
        # Normalize features
        image_features = image_features / image_features.norm(dim=-1, keepdim=True)
        text_features = text_features / text_features.norm(dim=-1, keepdim=True)
        
        # Compute logits
        logits = (image_features @ text_features.T) * self.clip_model.logit_scale.exp()
        
        # Compute CLIP contrastive loss
        clip_loss = (F.cross_entropy(logits, labels) + F.cross_entropy(logits.T, labels)) / 2
        
        # Compute Fisher Information Penalty
        fim_penalty = self.compute_fisher_penalty(logits, labels)
        
        # Compute Confidence Misalignment Penalty
        cmp_penalty = self.compute_cmp(logits, labels)
        
        # Total loss
        total_loss = clip_loss + self.lambda_fim * fim_penalty + self.lambda_cmp * cmp_penalty
        
        return {
            "loss": total_loss,
            "clip_loss": clip_loss,
            "fim_penalty": fim_penalty,
            "cmp_penalty": cmp_penalty,
            "logits": logits
        }

# Example usage
if __name__ == "__main__":
    # Load CLIP model
    device = "cuda" if torch.cuda.is_available() else "cpu"
    clip_model, preprocess = clip.load("ViT-B/32", device=device)
    
    # Initialize CalShift
    cal_shift = CalShift(clip_model).to(device)
    
    # Example data (would normally come from dataloader)
    images = torch.randn(4, 3, 224, 224).to(device)  # Batch of 4 images
    text_tokens = clip.tokenize(["a photo of a cat", "a photo of a dog"]).to(device)
    labels = torch.tensor([0, 1, 0, 1]).to(device)  # Example labels
    
    # Forward pass
    outputs = cal_shift(images, text_tokens, labels)
    print(f"Total loss: {outputs['loss'].item():.4f}")
    print(f"CLIP loss: {outputs['clip_loss'].item():.4f}")
    print(f"FIM penalty: {outputs['fim_penalty'].item():.4f}")
    print(f"CMP penalty: {outputs['cmp_penalty'].item():.4f}")
